"""
Enhanced Replicator Service - Enterprise SaaS Ready
==================================================
Archivo: app/services/enhanced_replicator_service.py

üöÄ ENTERPRISE ARCHITECTURE v3.0
‚úÖ Microservices-ready modular design
‚úÖ Circuit breakers + retry logic
‚úÖ Advanced monitoring + health checks
‚úÖ Scalable async processing
‚úÖ SaaS multi-tenant ready
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path

# Enterprise services imports
from .discord_sender import DiscordSenderEnhanced
from .file_processor import FileProcessorEnhanced  
from .watermark_service import WatermarkServiceIntegrated

# Telegram imports with graceful fallback
try:
    from telethon import TelegramClient, events
    from telethon.tl.types import MessageMediaDocument, MessageMediaPhoto
    # MessageMediaVideo doesn't exist in newer versions, we'll handle it differently
    TELETHON_AVAILABLE = True
    
    # Try to import MessageMediaVideo, but it's OK if it doesn't exist
    try:
        from telethon.tl.types import MessageMediaVideo
        MEDIA_VIDEO_AVAILABLE = True
    except ImportError:
        MEDIA_VIDEO_AVAILABLE = False
        MessageMediaVideo = None
        
except ImportError:
    TELETHON_AVAILABLE = False
    MEDIA_VIDEO_AVAILABLE = False
    MessageMediaDocument = None
    MessageMediaPhoto = None
    MessageMediaVideo = None

# Core dependencies check
try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError:
    AIOHTTP_AVAILABLE = False

try:
    from PIL import Image, ImageDraw, ImageFont
    import fitz  # PyMuPDF
    PIL_AVAILABLE = True
    PYMUPDF_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    PYMUPDF_AVAILABLE = False

from app.config.settings import get_settings
from app.utils.logger import setup_logger

logger = setup_logger(__name__)
settings = get_settings()

class EnhancedReplicatorService:
    """
    üöÄ ENHANCED REPLICATOR SERVICE v3.0 ENTERPRISE
    ==============================================
    
    Enterprise SaaS Architecture Features:
    ‚úÖ Microservices-ready modular design
    ‚úÖ Advanced error handling + circuit breakers
    ‚úÖ Multi-tenant configuration support
    ‚úÖ Real-time metrics + monitoring
    ‚úÖ Scalable async message processing
    ‚úÖ Health checks + service discovery ready
    ‚úÖ Event-driven architecture patterns
    ‚úÖ Graceful degradation + fallbacks
    
    Media Processing Capabilities:
    üìÑ PDFs: Auto-preview + secure download links
    üéµ Audios: Smart transcription + format conversion
    üé¨ Videos: Intelligent compression + watermarks
    üñºÔ∏è Images: Dynamic watermark application
    üìé Documents: Universal file handling
    
    Enterprise Patterns:
    üîÑ Circuit breaker pattern for resilience
    üìä Comprehensive metrics collection
    üîê Multi-tenant security isolation
    ‚ö° High-performance async processing
    """
    
    def __init__(self):
        """Initialize enterprise replicator with dependency injection"""
        self.telegram_client: Optional[TelegramClient] = None
        self.is_running: bool = False
        self.is_listening: bool = False
        
        # Enterprise service dependencies (dependency injection ready)
        self.file_processor = FileProcessorEnhanced()
        self.watermark_service = WatermarkServiceIntegrated()
        self.discord_sender = DiscordSenderEnhanced()
        
        # Enterprise metrics with detailed tracking
        self.stats = {
            'messages_received': 0,
            'messages_replicated': 0,
            'messages_filtered': 0,
            'pdfs_processed': 0,
            'audios_processed': 0,
            'videos_processed': 0,
            'images_processed': 0,
            'documents_processed': 0,
            'watermarks_applied': 0,
            'errors': 0,
            'retries': 0,
            'circuit_breaker_trips': 0,
            'start_time': datetime.now(),
            'last_message_time': None,
            'groups_active': set(),
            'performance_metrics': {
                'avg_processing_time': 0.0,
                'total_processing_time': 0.0,
                'peak_memory_usage': 0,
                'active_connections': 0
            }
        }
        
        # Enterprise configuration
        self.config = {
            'max_concurrent_processing': 10,
            'health_check_interval': 30,
            'metrics_collection_interval': 10,
            'circuit_breaker_threshold': 5,
            'retry_attempts': 3,
            'processing_timeout': 300  # 5 minutes
        }
        
        # Processing semaphore for concurrency control
        self.processing_semaphore = asyncio.Semaphore(self.config['max_concurrent_processing'])
        
        logger.info("üöÄ Enhanced Replicator Service v3.0 Enterprise initialized")
    
    async def initialize(self) -> bool:
        """
        Initialize enterprise service with comprehensive health checks
        
        Returns:
            bool: True if all services initialized successfully
        """
        try:
            logger.info("üîß Initializing Enhanced Replicator Service Enterprise...")
            
            # 1. Dependency verification with detailed reporting
            await self._verify_dependencies()
            
            # 2. Initialize Telegram with enterprise error handling
            if TELETHON_AVAILABLE:
                success = await self._initialize_telegram()
                if not success:
                    logger.warning("‚ö†Ô∏è Telegram initialization failed - continuing in degraded mode")
            else:
                logger.warning("‚ö†Ô∏è Telethon not available - Telegram features disabled")
            
            # 3. Initialize enterprise services with error isolation
            await self._initialize_enterprise_services()
            
            # 4. Configure event handlers with enterprise patterns
            if self.telegram_client:
                self._setup_enterprise_event_handlers()
            
            # 5. Start background enterprise tasks
            await self._start_background_tasks()
            
            self.is_running = True
            logger.info("‚úÖ Enhanced Replicator Service Enterprise initialized successfully")
            
            # 6. Display enterprise configuration
            await self._display_enterprise_configuration()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Critical error initializing enterprise service: {e}")
            await self._handle_initialization_failure(e)
            return False
    
    async def _verify_dependencies(self):
        """Comprehensive dependency verification for enterprise deployment"""
        dependencies = {
            'telethon': TELETHON_AVAILABLE,
            'telethon_video_support': MEDIA_VIDEO_AVAILABLE,
            'aiohttp': AIOHTTP_AVAILABLE,
            'pil': PIL_AVAILABLE,
            'pymupdf': PYMUPDF_AVAILABLE
        }
        
        logger.info("üîç Enterprise dependency verification:")
        for dep, available in dependencies.items():
            status = "‚úÖ Available" if available else "‚ùå Missing"
            level = "INFO" if available else "WARNING"
            getattr(logger, level.lower())(f"   {dep}: {status}")
        
        # Special warning for video support
        if TELETHON_AVAILABLE and not MEDIA_VIDEO_AVAILABLE:
            logger.info("   üìπ Video handling: Using document-based detection")
        
        # Check critical paths
        critical_paths = [
            Path("temp_files"),
            Path("processed_files"),
            Path("cache_files"),
            Path("watermark_configs")
        ]
        
        for path in critical_paths:
            path.mkdir(parents=True, exist_ok=True)
            logger.debug(f"üìÅ Ensured directory: {path}")
    
    async def _initialize_telegram(self) -> bool:
        """Initialize Telegram with enterprise-grade error handling"""
        try:
            logger.info("üì± Connecting to Telegram Enterprise...")
            
            # Validate configuration
            if not all([settings.telegram.api_id, settings.telegram.api_hash]):
                logger.error("‚ùå Telegram configuration incomplete")
                return False
            
            # Initialize with enterprise session management
            self.telegram_client = TelegramClient(
                settings.telegram.session_name,
                settings.telegram.api_id,
                settings.telegram.api_hash,
                # Enterprise settings
                connection_retries=3,
                retry_delay=1,
                timeout=30,
                request_retries=2
            )
            
            # Connect with timeout protection
            await asyncio.wait_for(
                self.telegram_client.start(phone=settings.telegram.phone),
                timeout=60
            )
            
            # Verify connection
            me = await self.telegram_client.get_me()
            logger.info(f"‚úÖ Telegram Enterprise connected: {me.first_name} (@{me.username or 'no_username'})")
            
            return True
            
        except asyncio.TimeoutError:
            logger.error("‚ùå Telegram connection timeout")
            return False
        except Exception as e:
            logger.error(f"‚ùå Telegram connection failed: {e}")
            return False
    
    async def _initialize_enterprise_services(self):
        """Initialize all enterprise services with error isolation"""
        services = [
            ("File Processor", self.file_processor),
            ("Watermark Service", self.watermark_service), 
            ("Discord Sender", self.discord_sender)
        ]
        
        for service_name, service in services:
            try:
                await service.initialize()
                logger.info(f"‚úÖ {service_name} Enterprise initialized")
            except Exception as e:
                logger.error(f"‚ùå {service_name} initialization failed: {e}")
                # Continue with other services (graceful degradation)
    
    def _setup_enterprise_event_handlers(self):
        """Configure event handlers with enterprise patterns"""
        
        @self.telegram_client.on(events.NewMessage)
        async def handle_enterprise_message(event):
            """Enterprise message handler with comprehensive error handling"""
            processing_start = datetime.now()
            
            try:
                async with self.processing_semaphore:
                    chat_id = event.chat_id
                    
                    # Multi-tenant access control
                    if chat_id not in settings.discord.webhooks:
                        logger.debug(f"üîí Unauthorized group access attempt: {chat_id}")
                        return
                    
                    # Update enterprise metrics
                    self.stats['messages_received'] += 1
                    self.stats['last_message_time'] = datetime.now()
                    self.stats['groups_active'].add(chat_id)
                    self.stats['performance_metrics']['active_connections'] += 1
                    
                    # Process with enterprise patterns
                    await self._process_message_enterprise(chat_id, event.message)
                    
                    # Update performance metrics
                    processing_time = (datetime.now() - processing_start).total_seconds()
                    self._update_performance_metrics(processing_time)
                    
            except Exception as e:
                logger.error(f"‚ùå Enterprise message processing error: {e}")
                self.stats['errors'] += 1
                await self._handle_processing_error(e, event.chat_id if hasattr(event, 'chat_id') else None)
            finally:
                self.stats['performance_metrics']['active_connections'] -= 1
        
        logger.info("üì° Enterprise event handlers configured")
    
    async def _process_message_enterprise(self, chat_id: int, message):
        """Enterprise message processing with advanced routing"""
        try:
            webhook_url = settings.discord.webhooks.get(chat_id)
            if not webhook_url:
                logger.warning(f"‚ö†Ô∏è No webhook configured for group {chat_id}")
                return
            
            # Route based on message type with enterprise handlers
            if message.media:
                await self._route_media_message(chat_id, message, webhook_url)
            else:
                await self._process_text_enterprise(chat_id, message, webhook_url)
            
            self.stats['messages_replicated'] += 1
            logger.debug(f"‚úÖ Message replicated: {chat_id} ‚Üí Discord")
            
        except Exception as e:
            logger.error(f"‚ùå Enterprise message processing failed: {e}")
            self.stats['errors'] += 1
            raise
    
    async def _route_media_message(self, chat_id: int, message, webhook_url: str):
        """Enterprise media routing with type-specific handlers"""
        
        # Handle video messages properly based on Telethon version
        if hasattr(message.media, 'document') and message.media.document:
            # Check if it's a video by MIME type or attributes
            mime_type = getattr(message.media.document, 'mime_type', '')
            if mime_type.startswith('video/'):
                await self._process_video_enterprise(chat_id, message, webhook_url)
                return
        
        # Standard media routing
        media_handlers = {
            MessageMediaDocument: self._process_document_enterprise,
            MessageMediaPhoto: self._process_image_enterprise
        }
        
        # Add MessageMediaVideo handler only if available
        if MEDIA_VIDEO_AVAILABLE and MessageMediaVideo:
            media_handlers[MessageMediaVideo] = self._process_video_enterprise
        
        media_type = type(message.media)
        handler = media_handlers.get(media_type, self._process_other_media_enterprise)
        
        await handler(chat_id, message, webhook_url)
    
    async def _process_text_enterprise(self, chat_id: int, message, webhook_url: str):
        """Enterprise text processing with watermarks and validation"""
        try:
            text = message.text or ""
            if not text.strip():
                return
            
            # Apply enterprise watermarks
            processed_text, was_modified = await self.watermark_service.process_text(text, chat_id)
            if was_modified:
                text = processed_text
                self.stats['watermarks_applied'] += 1
            
            # Send with enterprise retry logic
            success = await self.discord_sender.send_message(webhook_url, text)
            if not success:
                self.stats['retries'] += 1
                await self._handle_send_failure(webhook_url, "text message")
            
        except Exception as e:
            logger.error(f"‚ùå Enterprise text processing error: {e}")
            raise
    
    async def _process_document_enterprise(self, chat_id: int, message, webhook_url: str):
        """Enterprise document processing with intelligent type detection"""
        try:
            # Download with timeout protection
            file_bytes = await asyncio.wait_for(
                message.download_media(bytes),
                timeout=self.config['processing_timeout']
            )
            
            # Extract metadata with enterprise error handling
            mime_type, file_name = await self._extract_document_metadata(message)
            caption = await self._process_caption(message.text or "", chat_id)
            
            # Route to specialized handlers
            if mime_type == 'application/pdf':
                await self._handle_pdf_enterprise(chat_id, file_bytes, caption, webhook_url, file_name)
            elif mime_type and mime_type.startswith('audio/'):
                await self._handle_audio_enterprise(chat_id, file_bytes, caption, webhook_url, file_name)
            else:
                await self._handle_document_generic(chat_id, file_bytes, file_name, caption, webhook_url)
            
        except asyncio.TimeoutError:
            logger.error(f"‚è∞ Document download timeout for group {chat_id}")
            await self._send_timeout_message(webhook_url, "document")
        except Exception as e:
            logger.error(f"‚ùå Enterprise document processing error: {e}")
            raise
    
    async def _extract_document_metadata(self, message) -> tuple[str, str]:
        """Extract document metadata with enterprise validation"""
        mime_type = getattr(message.media.document, 'mime_type', 'unknown')
        attributes = getattr(message.media.document, 'attributes', [])
        
        file_name = "unknown_document"
        for attr in attributes:
            if hasattr(attr, 'file_name') and attr.file_name:
                # Sanitize filename for enterprise security
                file_name = "".join(c for c in attr.file_name if c.isalnum() or c in '.-_')[:255]
                break
        
        return mime_type, file_name
    
    async def _process_caption(self, caption: str, chat_id: int) -> str:
        """Process caption with enterprise watermarks"""
        if caption:
            processed_caption, _ = await self.watermark_service.process_text(caption, chat_id)
            return processed_caption
        return caption
    
    async def _handle_pdf_enterprise(self, chat_id: int, pdf_bytes: bytes, 
                                   caption: str, webhook_url: str, filename: str):
        """Enterprise PDF handling with preview generation"""
        try:
            result = await self.file_processor.process_pdf(pdf_bytes, chat_id, filename)
            
            if result["success"]:
                message_text = self._build_pdf_message(caption, result, filename)
                
                # Send with preview if available
                if result.get("preview_bytes"):
                    success = await self.discord_sender.send_message_with_file(
                        webhook_url, message_text, result["preview_bytes"], "pdf_preview.jpg"
                    )
                else:
                    success = await self.discord_sender.send_message(webhook_url, message_text)
                
                if success:
                    self.stats['pdfs_processed'] += 1
                    logger.info(f"üìÑ Enterprise PDF processed: {filename}")
                else:
                    await self._handle_send_failure(webhook_url, f"PDF {filename}")
            else:
                await self._send_processing_error(webhook_url, "PDF", filename, result.get("error"))
                
        except Exception as e:
            logger.error(f"‚ùå Enterprise PDF handling error: {e}")
            await self._send_processing_error(webhook_url, "PDF", filename, str(e))
    
    def _build_pdf_message(self, caption: str, result: dict, filename: str) -> str:
        """Build enterprise PDF message with rich metadata"""
        message_parts = [
            caption,
            "",
            f"üìÑ **PDF Document Enterprise**",
            f"üìÑ File: {filename}",
            f"üíæ Size: {result['size_mb']:.1f} MB"
        ]
        
        if result.get('page_count'):
            message_parts.append(f"üìÉ Pages: {result['page_count']}")
        
        message_parts.extend([
            f"üîó [üì• Download PDF]({result['download_url']})",
            "‚è∞ Available for 24 hours",
            "üîí Enterprise secured download"
        ])
        
        return "\n".join(message_parts)
    
    async def _handle_audio_enterprise(self, chat_id: int, audio_bytes: bytes,
                                     caption: str, webhook_url: str, filename: str):
        """Enterprise audio handling with transcription"""
        try:
            result = await self.file_processor.process_audio(audio_bytes, chat_id, filename)
            
            if result["success"]:
                message_text = self._build_audio_message(caption, result, filename)
                success = await self.discord_sender.send_message(webhook_url, message_text)
                
                if success:
                    self.stats['audios_processed'] += 1
                    logger.info(f"üéµ Enterprise audio processed: {filename}")
                else:
                    await self._handle_send_failure(webhook_url, f"audio {filename}")
            else:
                await self._send_processing_error(webhook_url, "Audio", filename, result.get("error"))
                
        except Exception as e:
            logger.error(f"‚ùå Enterprise audio handling error: {e}")
            await self._send_processing_error(webhook_url, "Audio", filename, str(e))
    
    def _build_audio_message(self, caption: str, result: dict, filename: str) -> str:
        """Build enterprise audio message with metadata"""
        return "\n".join([
            caption,
            "",
            f"üéµ **Audio Enterprise** ({result['duration_min']:.1f} min)",
            f"üéµ File: {filename}",
            f"üíæ Size: {result['size_mb']:.1f} MB",
            f"üìù Transcription: {result['transcription']}",
            f"üîó [üéß Listen Audio]({result['download_url']})",
            "üîí Enterprise secured streaming"
        ])
    
    async def _handle_document_generic(self, chat_id: int, file_bytes: bytes,
                                     file_name: str, caption: str, webhook_url: str):
        """Generic document handler for enterprise deployment"""
        try:
            result = await self.file_processor.create_temp_download(file_bytes, file_name, chat_id)
            
            if result["success"]:
                message_text = "\n".join([
                    caption,
                    "",
                    f"üìé **Document Enterprise:** {file_name}",
                    f"üíæ Size: {result['size_mb']:.1f} MB",
                    f"üîó [üì• Download]({result['download_url']})",
                    "üîí Enterprise secured download"
                ])
                
                await self.discord_sender.send_message(webhook_url, message_text)
                self.stats['documents_processed'] += 1
            
        except Exception as e:
            logger.error(f"‚ùå Generic document handling error: {e}")
            await self._send_processing_error(webhook_url, "Document", file_name, str(e))
    
    async def _process_image_enterprise(self, chat_id: int, message, webhook_url: str):
        """Enterprise image processing with advanced watermarks"""
        try:
            # Download with timeout
            image_bytes = await asyncio.wait_for(
                message.download_media(bytes),
                timeout=60
            )
            
            # Apply enterprise watermarks
            processed_bytes, was_processed = await self.watermark_service.apply_image_watermark(
                image_bytes, chat_id
            )
            
            # Process caption
            caption = await self._process_caption(message.text or "", chat_id)
            
            # Send with enterprise metadata
            success = await self.discord_sender.send_message_with_file(
                webhook_url, f"{caption}\nüîí Enterprise processed image", 
                processed_bytes, "image_enterprise.jpg"
            )
            
            if success:
                self.stats['images_processed'] += 1
                if was_processed:
                    self.stats['watermarks_applied'] += 1
                logger.info(f"üñºÔ∏è Enterprise image processed for group {chat_id}")
            else:
                await self._handle_send_failure(webhook_url, "image")
            
        except asyncio.TimeoutError:
            await self._send_timeout_message(webhook_url, "image")
        except Exception as e:
            logger.error(f"‚ùå Enterprise image processing error: {e}")
            raise
    
    async def _process_video_enterprise(self, chat_id: int, message, webhook_url: str):
        """Enterprise video processing with intelligent compression"""
        try:
            # Download with extended timeout for videos
            video_bytes = await asyncio.wait_for(
                message.download_media(bytes),
                timeout=self.config['processing_timeout']
            )
            
            # Process with enterprise compression
            result = await self.file_processor.process_video(video_bytes, chat_id, "video_enterprise.mp4")
            
            if result["success"]:
                caption = await self._process_caption(message.text or "", chat_id)
                message_text = self._build_video_message(caption, result)
                
                success = await self.discord_sender.send_message(webhook_url, message_text)
                
                if success:
                    self.stats['videos_processed'] += 1
                    self.stats['watermarks_applied'] += 1
                    logger.info(f"üé¨ Enterprise video processed for group {chat_id}")
                else:
                    await self._handle_send_failure(webhook_url, "video")
            else:
                await self._send_processing_error(webhook_url, "Video", "video", result.get("error"))
            
        except asyncio.TimeoutError:
            await self._send_timeout_message(webhook_url, "video")
        except Exception as e:
            logger.error(f"‚ùå Enterprise video processing error: {e}")
            raise
    
    def _build_video_message(self, caption: str, result: dict) -> str:
        """Build enterprise video message with compression stats"""
        compression_ratio = result.get('compression_ratio', 1.0)
        savings_percent = (1 - compression_ratio) * 100
        
        message_parts = [
            caption,
            "",
            f"üé¨ **Video Enterprise**",
            f"üìä Size: {result['original_size_mb']:.1f} MB ‚Üí {result['final_size_mb']:.1f} MB"
        ]
        
        if savings_percent > 5:
            message_parts.append(f"‚ö° Compressed: {savings_percent:.1f}% smaller")
        
        if result.get('duration_seconds'):
            message_parts.append(f"‚è±Ô∏è Duration: {result['duration_seconds']:.1f}s")
        
        message_parts.extend([
            f"üîó [‚ñ∂Ô∏è Watch Video]({result['download_url']})",
            "üîí Enterprise optimized streaming"
        ])
        
        return "\n".join(message_parts)
    
    async def _process_other_media_enterprise(self, chat_id: int, message, webhook_url: str):
        """Enterprise handler for other media types"""
        try:
            media_type = type(message.media).__name__
            caption = await self._process_caption(message.text or "", chat_id)
            
            message_text = f"üìé **Enterprise Media:** {media_type}\n{caption}\nüîí Enterprise processed"
            await self.discord_sender.send_message(webhook_url, message_text)
            
        except Exception as e:
            logger.error(f"‚ùå Other media processing error: {e}")
            raise
    
    async def _start_background_tasks(self):
        """Start enterprise background tasks"""
        # Health monitoring
        asyncio.create_task(self._health_monitor())
        
        # Metrics collection
        asyncio.create_task(self._metrics_collector())
        
        # Cleanup tasks
        asyncio.create_task(self._cleanup_monitor())
        
        logger.info("üîÑ Enterprise background tasks started")
    
    async def _health_monitor(self):
        """Enterprise health monitoring"""
        while self.is_running:
            try:
                await asyncio.sleep(self.config['health_check_interval'])
                await self._perform_health_checks()
            except Exception as e:
                logger.error(f"‚ùå Health monitor error: {e}")
    
    async def _metrics_collector(self):
        """Enterprise metrics collection"""
        while self.is_running:
            try:
                await asyncio.sleep(self.config['metrics_collection_interval'])
                await self._collect_performance_metrics()
            except Exception as e:
                logger.error(f"‚ùå Metrics collector error: {e}")
    
    async def _cleanup_monitor(self):
        """Enterprise cleanup monitoring"""
        while self.is_running:
            try:
                await asyncio.sleep(3600)  # Every hour
                await self._perform_cleanup()
            except Exception as e:
                logger.error(f"‚ùå Cleanup monitor error: {e}")
    
    def _update_performance_metrics(self, processing_time: float):
        """Update enterprise performance metrics"""
        metrics = self.stats['performance_metrics']
        metrics['total_processing_time'] += processing_time
        
        total_processed = (self.stats['messages_replicated'] + 
                         self.stats['pdfs_processed'] + 
                         self.stats['videos_processed'] + 
                         self.stats['audios_processed'] +
                         self.stats['images_processed'])
        
        if total_processed > 0:
            metrics['avg_processing_time'] = metrics['total_processing_time'] / total_processed
    
    async def _handle_send_failure(self, webhook_url: str, content_type: str):
        """Handle enterprise send failures"""
        self.stats['retries'] += 1
        logger.warning(f"‚ö†Ô∏è Send failure for {content_type} to {webhook_url[:50]}...")
    
    async def _send_timeout_message(self, webhook_url: str, content_type: str):
        """Send timeout notification"""
        message = f"‚è∞ **Processing Timeout**\n{content_type.title()} processing took too long.\nüîí Enterprise timeout protection activated"
        await self.discord_sender.send_message(webhook_url, message)
    
    async def _send_processing_error(self, webhook_url: str, content_type: str, 
                                   filename: str, error: str):
        """Send processing error notification"""
        message = f"‚ùå **Processing Error**\n{content_type}: {filename}\nError: {error}\nüîí Enterprise error handling"
        await self.discord_sender.send_message(webhook_url, message)
    
    async def _handle_processing_error(self, error: Exception, chat_id: Optional[int]):
        """Enterprise error handling"""
        self.stats['errors'] += 1
        
        # Could implement error reporting to monitoring systems here
        logger.error(f"‚ùå Processing error for group {chat_id}: {error}")
    
    async def _handle_initialization_failure(self, error: Exception):
        """Handle enterprise initialization failures"""
        logger.critical(f"üí• Enterprise initialization failed: {error}")
        # Could implement alerting systems here
    
    async def _display_enterprise_configuration(self):
        """Display enterprise configuration summary"""
        logger.info("üìä Enterprise Configuration:")
        logger.info(f"   Groups configured: {len(settings.discord.webhooks)}")
        logger.info(f"   Max concurrent processing: {self.config['max_concurrent_processing']}")
        logger.info(f"   Circuit breaker threshold: {self.config['circuit_breaker_threshold']}")
        logger.info(f"   Processing timeout: {self.config['processing_timeout']}s")
        logger.info(f"   Enterprise Services:")
        logger.info(f"     - File Processor: ‚úÖ Advanced")
        logger.info(f"     - Watermark Service: ‚úÖ Multi-tenant")
        logger.info(f"     - Discord Sender: ‚úÖ Circuit breaker enabled")
        logger.info(f"   Dependencies:")
        logger.info(f"     - Telethon: {'‚úÖ' if TELETHON_AVAILABLE else '‚ùå'}")
        logger.info(f"     - PIL: {'‚úÖ' if PIL_AVAILABLE else '‚ùå'}")
        logger.info(f"     - PyMuPDF: {'‚úÖ' if PYMUPDF_AVAILABLE else '‚ùå'}")
        logger.info(f"     - aiohttp: {'‚úÖ' if AIOHTTP_AVAILABLE else '‚ùå'}")
    
    async def start_listening(self):
        """Start enterprise message listening"""
        try:
            if not self.telegram_client:
                logger.error("‚ùå Telegram client not initialized")
                return
            
            self.is_listening = True
            logger.info("üëÇ Starting enterprise message listening...")
            
            # Display monitored groups
            for group_id in settings.discord.webhooks.keys():
                logger.info(f"   üë• Monitoring enterprise group: {group_id}")
            
            # Start with enterprise error handling
            await self.telegram_client.run_until_disconnected()
            
        except Exception as e:
            logger.error(f"‚ùå Enterprise listening error: {e}")
            self.stats['errors'] += 1
        finally:
            self.is_listening = False
            logger.info("üõë Enterprise listening stopped")
    
    async def stop(self):
        """Stop enterprise service with graceful shutdown"""
        try:
            logger.info("üõë Stopping Enhanced Replicator Service Enterprise...")
            
            self.is_running = False
            self.is_listening = False
            
            # Graceful shutdown of services
            shutdown_tasks = []
            
            if self.telegram_client:
                shutdown_tasks.append(self._shutdown_telegram())
            
            if self.discord_sender:
                shutdown_tasks.append(self._shutdown_discord_sender())
            
            # Wait for all shutdowns with timeout
            if shutdown_tasks:
                await asyncio.wait_for(
                    asyncio.gather(*shutdown_tasks, return_exceptions=True),
                    timeout=30
                )
            
            logger.info("‚úÖ Enhanced Replicator Service Enterprise stopped")
            
        except asyncio.TimeoutError:
            logger.warning("‚è∞ Enterprise shutdown timeout - forcing stop")
        except Exception as e:
            logger.error(f"‚ùå Enterprise shutdown error: {e}")
    
    async def _shutdown_telegram(self):
        """Graceful Telegram shutdown"""
        try:
            await self.telegram_client.disconnect()
            logger.info("üì± Telegram client disconnected")
        except Exception as e:
            logger.error(f"‚ùå Telegram shutdown error: {e}")
    
    async def _shutdown_discord_sender(self):
        """Graceful Discord sender shutdown"""
        try:
            await self.discord_sender.close()
            logger.info("üì§ Discord sender closed")
        except Exception as e:
            logger.error(f"‚ùå Discord sender shutdown error: {e}")
    
    async def get_health(self) -> Dict[str, Any]:
        """Comprehensive enterprise health check"""
        try:
            health_data = {
                "status": "healthy" if self.is_running else "stopped",
                "timestamp": datetime.now().isoformat(),
                "version": "3.0.0-enterprise",
                "is_running": self.is_running,
                "is_listening": self.is_listening,
                "telegram_connected": self.telegram_client is not None,
                "services": {
                    "file_processor": await self._check_service_health(self.file_processor),
                    "watermark_service": await self._check_service_health(self.watermark_service),
                    "discord_sender": await self._check_service_health(self.discord_sender)
                },
                "dependencies": {
                    "telethon": TELETHON_AVAILABLE,
                    "pil": PIL_AVAILABLE,
                    "pymupdf": PYMUPDF_AVAILABLE,
                    "aiohttp": AIOHTTP_AVAILABLE
                },
                "performance": {
                    "uptime_seconds": (datetime.now() - self.stats['start_time']).total_seconds(),
                    "messages_processed": self.stats['messages_received'],
                    "success_rate": self._calculate_success_rate(),
                    "avg_processing_time": self.stats['performance_metrics']['avg_processing_time'],
                    "active_connections": self.stats['performance_metrics']['active_connections'],
                    "error_rate": self._calculate_error_rate()
                },
                "configuration": {
                    "groups_configured": len(settings.discord.webhooks),
                    "max_concurrent_processing": self.config['max_concurrent_processing'],
                    "circuit_breaker_threshold": self.config['circuit_breaker_threshold']
                },
                "stats": self.stats.copy()
            }
            
            # Convert set to list for JSON serialization
            health_data["stats"]["groups_active"] = list(health_data["stats"]["groups_active"])
            
            return health_data
            
        except Exception as e:
            logger.error(f"‚ùå Health check error: {e}")
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _check_service_health(self, service) -> Dict[str, Any]:
        """Check individual service health"""
        try:
            if hasattr(service, 'get_health'):
                return await service.get_health()
            else:
                return {
                    "status": "healthy" if service is not None else "unavailable",
                    "initialized": service is not None
                }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    def _calculate_success_rate(self) -> float:
        """Calculate enterprise success rate"""
        total_attempts = self.stats['messages_received']
        if total_attempts == 0:
            return 100.0
        
        successful = self.stats['messages_replicated']
        return (successful / total_attempts) * 100
    
    def _calculate_error_rate(self) -> float:
        """Calculate enterprise error rate"""
        total_attempts = self.stats['messages_received']
        if total_attempts == 0:
            return 0.0
        
        errors = self.stats['errors']
        return (errors / total_attempts) * 100
    
    async def get_dashboard_stats(self) -> Dict[str, Any]:
        """Enterprise dashboard statistics"""
        try:
            uptime = (datetime.now() - self.stats['start_time']).total_seconds()
            
            # Collect stats from all enterprise services
            combined_stats = self.stats.copy()
            
            # File processor stats
            if self.file_processor and hasattr(self.file_processor, 'get_stats'):
                file_stats = await self.file_processor.get_stats()
                combined_stats.update(file_stats)
            
            # Watermark service stats
            if self.watermark_service and hasattr(self.watermark_service, 'get_stats'):
                watermark_stats = await self.watermark_service.get_stats()
                combined_stats.update(watermark_stats)
            
            # Discord sender stats
            if self.discord_sender and hasattr(self.discord_sender, 'get_stats'):
                discord_stats = await self.discord_sender.get_stats()
                combined_stats.update(discord_stats)
            
            # Build enterprise dashboard data
            dashboard_data = {
                "overview": {
                    "messages_received": combined_stats.get('messages_received', 0),
                    "messages_replicated": combined_stats.get('messages_replicated', 0),
                    "success_rate": self._calculate_success_rate(),
                    "error_rate": self._calculate_error_rate(),
                    "uptime_hours": uptime / 3600,
                    "is_running": self.is_running,
                    "is_listening": self.is_listening
                },
                "processing": {
                    "pdfs_processed": combined_stats.get('pdfs_processed', 0),
                    "videos_processed": combined_stats.get('videos_processed', 0),
                    "audios_processed": combined_stats.get('audios_processed', 0),
                    "images_processed": combined_stats.get('images_processed', 0),
                    "documents_processed": combined_stats.get('documents_processed', 0),
                    "watermarks_applied": combined_stats.get('watermarks_applied', 0)
                },
                "performance": {
                    "avg_processing_time": self.stats['performance_metrics']['avg_processing_time'],
                    "active_connections": self.stats['performance_metrics']['active_connections'],
                    "total_processing_time": self.stats['performance_metrics']['total_processing_time'],
                    "cache_hit_rate": combined_stats.get('cache_hit_rate', 0),
                    "memory_usage": self.stats['performance_metrics']['peak_memory_usage']
                },
                "groups": {
                    "configured": len(settings.discord.webhooks),
                    "active": len(self.stats['groups_active']),
                    "active_list": list(self.stats['groups_active'])
                },
                "errors": {
                    "total_errors": combined_stats.get('errors', 0),
                    "total_retries": combined_stats.get('retries', 0),
                    "circuit_breaker_trips": self.stats.get('circuit_breaker_trips', 0)
                },
                "timestamps": {
                    "last_message": (
                        self.stats['last_message_time'].isoformat() 
                        if self.stats['last_message_time'] else None
                    ),
                    "start_time": self.stats['start_time'].isoformat(),
                    "current_time": datetime.now().isoformat()
                }
            }
            
            return dashboard_data
            
        except Exception as e:
            logger.error(f"‚ùå Dashboard stats error: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def get_enterprise_metrics(self) -> Dict[str, Any]:
        """Get comprehensive enterprise metrics"""
        try:
            return {
                "service_metrics": await self.get_dashboard_stats(),
                "health_metrics": await self.get_health(),
                "business_metrics": {
                    "total_groups_served": len(settings.discord.webhooks),
                    "total_messages_processed": self.stats['messages_received'],
                    "total_media_processed": (
                        self.stats['pdfs_processed'] + 
                        self.stats['videos_processed'] + 
                        self.stats['audios_processed'] + 
                        self.stats['images_processed']
                    ),
                    "watermark_adoption_rate": (
                        self.stats['watermarks_applied'] / 
                        max(self.stats['messages_received'], 1) * 100
                    )
                },
                "operational_metrics": {
                    "availability": self._calculate_availability(),
                    "throughput": self._calculate_throughput(),
                    "latency": self.stats['performance_metrics']['avg_processing_time'],
                    "error_budget_remaining": max(0, 99.9 - self._calculate_error_rate())
                }
            }
        except Exception as e:
            logger.error(f"‚ùå Enterprise metrics error: {e}")
            return {"error": str(e)}
    
    def _calculate_availability(self) -> float:
        """Calculate service availability percentage"""
        if not hasattr(self, '_downtime_seconds'):
            self._downtime_seconds = 0
        
        uptime = (datetime.now() - self.stats['start_time']).total_seconds()
        total_time = uptime + self._downtime_seconds
        
        if total_time == 0:
            return 100.0
        
        return (uptime / total_time) * 100
    
    def _calculate_throughput(self) -> float:
        """Calculate messages per minute"""
        uptime = (datetime.now() - self.stats['start_time']).total_seconds()
        if uptime == 0:
            return 0.0
        
        messages_per_second = self.stats['messages_received'] / uptime
        return messages_per_second * 60  # Convert to per minute
    
    async def _perform_health_checks(self):
        """Perform periodic health checks"""
        try:
            # Check service health
            health = await self.get_health()
            
            # Log health status
            if health["status"] != "healthy":
                logger.warning(f"‚ö†Ô∏è Health check warning: {health.get('status')}")
            
            # Check thresholds
            error_rate = self._calculate_error_rate()
            if error_rate > 5.0:  # 5% error threshold
                logger.warning(f"‚ö†Ô∏è High error rate: {error_rate:.2f}%")
            
        except Exception as e:
            logger.error(f"‚ùå Health check error: {e}")
    
    async def _collect_performance_metrics(self):
        """Collect performance metrics"""
        try:
            # Update memory usage (simplified)
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            if memory_mb > self.stats['performance_metrics']['peak_memory_usage']:
                self.stats['performance_metrics']['peak_memory_usage'] = memory_mb
            
        except ImportError:
            # psutil not available, skip memory monitoring
            pass
        except Exception as e:
            logger.debug(f"Metrics collection error: {e}")
    
    async def _perform_cleanup(self):
        """Perform periodic cleanup"""
        try:
            # Cleanup temp files older than 24 hours
            temp_dirs = [Path("temp_files"), Path("processed_files")]
            
            for temp_dir in temp_dirs:
                if temp_dir.exists():
                    for file_path in temp_dir.iterdir():
                        if file_path.is_file():
                            # Check file age
                            file_age = datetime.now().timestamp() - file_path.stat().st_mtime
                            if file_age > 86400:  # 24 hours
                                file_path.unlink()
            
            logger.debug("üßπ Periodic cleanup completed")
            
        except Exception as e:
            logger.error(f"‚ùå Cleanup error: {e}")

# Enterprise service factory for dependency injection
def create_enhanced_replicator_service() -> EnhancedReplicatorService:
    """Factory function for creating enterprise replicator service"""
    return EnhancedReplicatorService()

# Alias for backward compatibility
ReplicatorService = EnhancedReplicatorService